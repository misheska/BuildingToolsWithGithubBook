== Jekyll: nouveau, yet antiquated, blogging on GitHub

=== What is Jekyll?

If you visit GitHub and go to the jekyll repository you'll see it state that 
"Jekyll is a blog-aware, static site generator in Ruby." What does this mean?
Jekyll is a set of technologies for building entire web sites. There are
probably as many tools for generating web sites as there are websites,
though, so why does Jekyll deserve notice over others? 
The core Jekyll tool provides just enough to build a beautiful site,
but the authors stopped there. Many other web site tools layer more
and more complicated processes and require complicated backends for
hosting. Jekyll is an antidote to this way of thinking. You can layer
many other pieces onto Jekyll and build ever more complex sites if you
want to, but you don't have to. Often, thinking simple leads to a much
more elegant way to do things.

More concretely, Jekyll specifies a format that will take a set of
files and compile them into HTML. Jekyll builds on top of two proven
tools: Markdown, a markup language which is surprisingly readable and
surprisingly expressive, and Liquid Templates, a simple programming
language which gives you just enough components to build modern web
pages requiring conditionals and loops, but safe enough that you can
run untrusted pages on public servers. With these two technologies and
agreement on a layout structure, Jekyll can build very complicated web
sites without starting from a complicated structure of files and
technologies. 

Jekyll works natively with GitHub because a Jekyll blog is
stored as a Git repository. When you push files into GitHub from a
repository which GitHub recognizes as a Jekyll site, GitHub
automatically rebuilds the site for you.
Jekyll is an open source generator and defines a format for your
source files, a format which other tools can easily understand and
operate upon. This means you can build your own tools to interact with
a Jekyll blog. Combining an open source tool like Jekyll with a well
written API like the GitHub API makes for some powerful publishing
tools.

Oddly enough, Jekyll takes us back to the advent of
the web when all pages were static, and often created by hand. 
Nowadays most modern sites are dynamically generated using a
database backend. Jekyll suprises us with a tool that recognizes we
only need to be dynamic when new content is created not when a new visitor
requests the same page as the previous visitor. Unexpectedly, this
acknoledgement results in a massive reduction in
complexity and freedom. When you look at a site built by Jekyll, you
are looking at a set of static files, backed by nothing more complex
than the same web server technologies available in 1998.

==== The need for Jekyll

Though you won't see it in the documentation, the popularity of Jekyll
is due in large part to the desire of bloggers, especially very technical ones,
wanting a blogging tool option other than Wordpress, the 800 lb.
gorilla in the room. For many bloggers, Wordpress is a poor
choice of blogging tools. Of course, there is always language snobbery
when considering any tool, but Wordpress is built on a language, PHP, which
is widely reviled by many developers. Because PHP is
a more accessible language than other languages, the choice of PHP has
fostered a large community of plugin developers. Unfortunately, this
community is fractured, and the plugins which arise from it are at
best poorly documented and poorly integrated, and at worst, poorly
designed and buggy. While Wordpress does often have a plugin for
anything you need, the problem it solves often creates more problems
in the long term when scalability or database optimization or security, for
example, become concerns.

Jekyll is interesting because of the components which are not present
when compared against Wordpress. Jekyll does not require a database.
Jekyll does not require you know how to write in HTML. While Wordpress
ostensibly advertises itself as a tool which can be used without
knowledge of these technologies, talk to those of us who have struggled with
recovery of a mangled database after installation of a new Wordpress plugin,
or resolving scalability issues on a large Wordpress site, or
analyzing and fixing broken HTML produced by the Wordpress editor.
We'll tell you that, when using Wordpress, you don't need to know about MySQL or
HTML at all, because it is already too late by then to fix whatever
problem you are facing.

Jekyll responds to these concerns in a really elegant way. Instead of
authoring in HTML, you author in a simple and readable language called
Markdown, which the Jekyll engine converts automatically to HTML
for you. Instead of storing posts and other data inside a MySQL
database, you use the filesystem to store posts and layouts and then
regenerate the entire site when infrequent changes are made. And, to
faciliate interaction, you use client side JavaScript plugins instead
of pushing that interaction into your database. Jekyll has found a
sweet spot with a simple technology set that makes your life easier
and makes beautiful blogs and simple web sites. And, the biggest
benefit of doing things the "Jekyll" way is that all dependencies can
sit within a repository, and this means your entire site can be hosted
on GitHub. 

==== The father of Jekyll

Like many of the open source technologies in heavy usage at GitHub,
jekyll was originally developed by Tom Preson Warner, one of the
co-founders of GitHub, and Nick Quaranto, of 37 Signals, though there
are now thousands of contributors to the Jekyll codebase. Like many
open source projects, the strength of the tool comes not from the
brilliance of the original developers or the brilliance of the idea,
but the way that those original developers cultivated community and
involvement among the users of the tool.

==== Running Jekyll locally

To use jekyll, you'll need the `jekyll` gem. You could do this by
running the command:

[source,bash]
------
$ gem install jekyll
------

There are two issues with doing installation this way. The first is that any
commands we run inside the command line are lost to us and the world
(other than in our private shell history file). The second is that if
we are going to publish any of our sites to GitHub, we will want to
make sure we are matching the exact versions of Jekyll and its
dependencies so that a site that works on our local laptop also works
when published into GitHub. If you don't take care of this, you'll
occasionally get an email like this from GitHub: 

[quote]
----

 The page build failed with the following error:
 
 page build failed

 For information on troubleshooting Jekyll see
 https://help.github.com/articles/using-jekyll-with-pages#troubleshooting
 If you have any questions please contact GitHub Support.


----

The fix for these two issues is a simple one. You've probably seen other
chapters using a `Gemfile` to install ruby libraries. Instead of
using a manual command like `bundle` to install from the command line,
let's put this dependency into the Gemfile. Then, anyone else using
this repository can run the command `bundle install` and install the
correct dependencies. And, instead of using the `jekyll` gem directly, use the
`github-pages` gem which synchronizes your jekyll gem versions with
those on GitHub. If you do get the email above, run the command `bundle update`
to make sure that everything is properly setup and synchronized and
generally this will reproduce the issues on your local setup, which is
a much faster place to fix them.

[source,bash]
------
$ printf "gem 'github-pages' >> Gemfile
$ bundle install
------

Creating and managing your dependencies inside a Gemfile is the smart
way to your jekyll tool synced with the version running on GitHub.

==== Jekyll quick start

Now that we have our required tools, let's create a simple blog. Run
these commands.

[source,bash]
-----
$ jekyll new myblog
$ cd myblog
-----

The `jekyll new` commands creates the necessary structure for a
minimal jekyll blog. Taking a look inside the directory, you'll see a
few files which comprise the structure of a basic Jekyll blog. 

The `jekyll new` command installs two CSS files: one for
the blog (`main.css`) and one for syntax highlighting (`syntax.css`).
Remember, you are in full control of this site; the `main.css` file is
simply boilerplate which you can completely throw away if it does not
suit your needs. The syntax file helps when including code snippets
and contains syntax highlighting CSS which prettifies many programming
languages.

Installation of a new blog
comes with a .gitignore file as well which contains one entry:
`_site`. When you use the jekyll library to build your site locally,
all files are by default built into the _site directory.
This .gitignore file prevents those files from being included inside
your repository as they are overwritten by the jekyll command on
GitHub when your files are pushed up to GitHub.

[NOTE]
====
The `jekyll new` command does not create or initialize a new git
repository for you with your files. If you want to do this, you will need to
use the `git init` command. The jekyll initialization command does create the
proper structure for you to easily add all files to a git repository;
just use `git add .; git commit` and your gitignore file will be added
and configure your repository to ignore unnecessary files like the
`_site` directory.
====

All your blog posts are stored in the `_posts` directory. Jekyll sites
are not required to have a `_posts` directory (you can use jekyll with
any kind of static site) but if you do include files in this directory
jekyll handles them in a special way. If you look in the `_posts`
directory now, you see that the jekyll initialization command has
created your first post for you, something like
`_posts/2014-03-03-welcome-to-jekyll.Markdown`. These posts have a
special naming format: the title of the post (with any whitespace replaced with
hyphens) trailed by the date and then an extension (either `.Markdown`
or `.md` for Markdown files, or `.textile` for Textile)

Your new jekyll blog also comes with a few HTML files: an `index.html` file
which is the starting point for your blog, and several layout files
which are used as wrappers when generating your content. If you look
in the `_layouts` directory, notice there is a file named
`default.html` and another named `post.html`. These files are the
layout files, files which are wrapped around all generated content,
like those from your Markdown formatted blog posts. For
example, the `post.html` file is wrapped around the generated content
of each file stored inside the `_posts` directory. First the markup content is
turned into HTML and then the layout wrapper is applied. If you look
inside each of the files inside the `_layouts` directory, you will see
that each contains a placeholder with `{{ content }}`. This
placeholder is replaced with the generated content from other files.

These placeholders are actually a markup language on their own:
"Liquid Templating." Liquid Templating (or Liquid Markup) was developed and open sourced by
Shopify, and is a safe way to include programmatic constructs (like loops
and variables) into a template, without exposing the rendering context
to a full fledged programming environment. Shopify wanted to build a
way for untrusted users of their public facing systems to upload
dynamic content but not worry that the markup language would permit
malicious activity; for example, given a full fledged embedded
programming language, they would open themselves to attack if a user
wrote code to open network connections to sites on their internal
networks. Templating languages like PHP or ERB (embedded ruby
templates, popular with the Ruby on Rails framework) allow fully
embedded code snippets and while this is very powerful when you have full control
over your source documents, it can be dangerous to provide a mechanism
where that embedded code could look like `system("rm -rf /")`. 
Liquid provides many of the benefits of embedded programming templates,
without the dangers. 

Lastly, your jekyll directory has a special file called `_config.yml`.
This is the jekyll configuration file. Peering into it, you'll see it
is very basic:

[source,yaml]
-----
name: Your New Jekyll Site
markdown: redcarpet
pygments: true

-----

We only have three lines to contend with and they are simple to
understand: the name of our site, the Markdown parser used by our
jekyll command, and whether to use pygments to do syntax highlighting.

To view this site locally run this command:

[source,bash]
-----
$ jekyll serve
-----

This command builds the entirety of your jekyll directory, and then
starts a mini web server to serve the files up to you. If you then
visit `http://localhost:4000` in your web browser, you will see
something the front page of your site and a single blog post listed in
the index.

[[bare-jekyll-site]]
.A bare Jekyll site
image::images/jekyll-bare.png[A bare Jekyll site]

Clicking into the link inside the "Blog Posts" section, you will then
see your first post.

[[a-sample-post]]
.A sample post
image::images/jekyll-welcome.png[A sample post co-authored by Tom Preston-Warner]

Our jekyll initialization command created this new post for us. This page
is backed by the Markdown file inside the _posts directory which we
saw earlier. 

[source,yaml]
-----
---
layout: post
title:  "Welcome to Jekyll!"
date:   2014-03-03 12:56:40
categories: jekyll update
---

You'll find this post in your `_posts` directory - edit this post and re-build (or run with the `-w` switch) to see your changes!
To add new posts, simply add a file in the `_posts` directory that follows the convention: YYYY-MM-DD-name-of-post.ext.

Jekyll also offers powerful support for code snippets:

{% highlight ruby %}
def print_hi(name)
  puts "Hi, #{name}"
end
print_hi('Tom')
#=> prints 'Hi, Tom' to STDOUT.
{% endhighlight %}

Check out the [Jekyll docs][jekyll] for more info on how to get the most out of Jekyll. File all bugs/feature requests at [Jekyll's GitHub repo][jekyll-gh].

[jekyll-gh]: https://github.com/mojombo/jekyll
[jekyll]:    http://jekyllrb.com

-----

Hopefully you'll agree this is a fairly intuitive and readable
alternative to raw HTML. This simplicity and readability is one of the
major benefits of using Jekyll. Your source files maintain a
readability that allows you to focus on the content itself, not on the
technology that will eventually make them beautiful. Let's go over
this file and investigate some of the important pieces.

==== YFM: YAML Front Matter

Starting at the top, we see the YAML Front
Matter (YFM). YFM is a snippet of YAML ("YAML Aint Markup Language")
delimited by three hyphens on both the top and bottom. YAML is a simple structured
data serialization language used by many open source projects instead
of XML. Many people find it more readable and editable by humans
than XML. The YFM in this file shows a few configuration options: a
layout, the title, the date and a list of categories. 

The layout specified references one of the files in our `_layouts`
directory. If you don't specify a layout file in the YFM, then Jekyll
assumes you want to use a file called `default.html` to wrap your
content. You can easily imagine adding your own custom layout files
to this directory and then overriding them in the YFM. If you look at
this file, you see that it manually specifies the `post` layout.

The title is used to generate the `<title>` tag and can be used
anywhere else you need it inside your template using the double
braces syntax from Liquid: `{{ page.title }}`. Notice that any
variable from the `_config.yml` file is prefixed with the `site.`
namespace, while variables from your YFM are prefixed with `page.`. 
Though the title matches the filename (after replacing
spaces with hyphens), changing the title in the YFM does not affect
the name of the URL generated by Jekyll. If you want to change the URL, you need to
rename the file itself. This is a nice benefit if you need to slightly modify the
title and don't want to damage preexisting URLs.

The date and categories are two other variables included in the YFM.
They are completely optional and strangely unused by the structure and
templates created by default using the Jekyll initializer. They do
provide additional context to the post, but are only stored in the
Markdown file and not included inside the generated content itself.
The categories list is often used to generate an index file of
categories with a list of each post included in a category. If you
come from a Wordpress background, you'll likely have used categories.
These are generated dynamically from the MySQL database each time you
request a list of them, but in Jekyll this file is staticly generated.
If you wanted something more dynamic, you could imagine generating a
JSON file with these categories and files, and then building a
JavaScript widget which requests this file and then does something
more interactive on the client side. Jekyll can take any template file
and convert it to JSON (or any other format) -- you are not limited to
just generating HTML files. 

YFM is completely optional. A post or page can be rendered into your
Jekyll site without any YFM inside it. Without YFM, your page is
rendered using the defaults for those variables, so make sure the
default template, at the very least, is what you expect will wrap
around all pages left with unspecified layouts.

One important default variable for YFM is the published variable. This
variable is set to true by default. This means that if you create a
file in your Jekyll repository and do not manually specify the
published setting, it will be published automatically. If you set the
variable to false then the post will not be published. With
private repositories you can keep the contents of draft posts entirely
private until writing has completed by making sure published is set
to false. Unfortunately, not all tools that help you create Jekyll
Markdown files remember to set the published variable explicitly
inside of YFM, so make sure you check before committing the file to
your repository if there is something you don't yet want published. 

==== Jekyll markup

Going past the YFM, we can start to see the structure of 
Markdown files. Markdown files can be, at their simplest, just textual
information without any formatting characters. In fact, if your layout files are
well done, you can definitely create great blog posts without any
fancing formatting, just pure textual content. 

But, with a few small Markdown additions, you can really make posts
shine. One of the first Markdown components we notice is the backtick
character, which is used to wrap small spans of code (or code-ish
information, like filenames in this case). As you use more and more
Markdown, you'll find Markdown to be insidiously clever in the way it
provides formatting characters without the onerous weight that HTML
requires to offer the same explicit formatting.

Links can be specified using `[format][link]`, where `link` is the
fully qualified URL (like "http://example.com"), or a reference to a
link at the bottom of the page. In our page we have two references,
keyed as `jekyll-gh` and `jekyll`; we can then use these inside our
page with syntax like `[Jekyll's GitHub repo][jekyll-gh]`. Using
references has an additional benefit in that you can use the link more
than once by its short name.

Though not offered in the sample, Markdown provides an easy way to
generate headers of varying degrees. To add a header, use the `#`
character, and repeat the `#` character to build smaller headers.
These delimiters simply map to the H tag; two hash characters `##`
turns into a `<h2>` tag. Building text enclosed by `<h3>` tags looks
like `### Some Text`. You can optionally match the same number of hash
symbols at the end of the line if you find it more expressive (`###
Some Text ###`), but you don't have to.

Markdown offers easy shortcuts for most HTML elements: numbered and
unordered lists, emphasis and more. And, if you cannot find a
Markdown equivalent, you can embed normal HTML right next to
Markdown formatting characters. The best way to write Markdown is to
keep a
https://github.com/adam-p/Markdown-here/wiki/Markdown-Cheatsheet:[Markdown
cheat sheet] near you when writing. John Gruber from Daring 
Fireball invented Markdown, and his site has a more in depth
description of the how and why of Markdown.

==== Using the jekyll command

Running `jekyll --help` will show you the options for running jekyll.
You already saw the `jekyll serve` command which builds the files into
the `_site` directory and then starts a webserver with its root at that directory. 
If you start to use this mechanism to build your Jekyll sites then
there are a few other switches you'll want to learn about.

If you are authoring and adjusting a page often, and switching back
into your browser to see what it looks like, you'll find utility in
the `-w` switch ("watch"). This can be used to automatically
regenerate the entire site if you make changes to any of the source
files. If you edit a post file and save it, that file will be
regenerated automatically. Without the `-w` switch you would need to
kill the jekyll server, and then restart it. 

[CAUTION]
====
The jekyll watch switch does reload all HTML and markup files, but
does not reload the _config.yml file. If you make changes to it, you
will need to stop and restart the server.
====

If you are running multiple Jekyll sites on the same laptop, you'll
quickly find that the second instance of `jekyll serve` fails because
it cannot open port 4000. In this case, use `jekyll --port 4010` to
open port 4010 (or whatever port you wish to use instead).

==== Privacy Levels with Jekyll

Jekyll repositories on GitHub can be either public or private
repositories. If your repository is public you can host public content
generated from the Jekyll source files without publishing the source
files themselves. Remember, as noted previously, that any file without
`publishing: false` inside the YFM will be made public the moment you
push it into your repository.

==== Themes

Jekyll does not support theming internally, but it is trivial to add
any CSS files or entire CSS frameworks. You could do this yourself, or
you could just fork an existing jekyll blog which has the theming you
like. The most popular themed Jekyll blog structure is Octopress. 

==== Publishing on GitHub

Once you have your blog created, you can easily publish it to GitHub.
There are two ways which you can publish Jekyll blogs: 

* As a github.io site
* On a domain you own

Github offers free personal blogs which are hosted on the github.io
domain. And, you can host any site with your own domain name with a
little bit of configuration.

===== Using a GitHub.io Jekyll Blog

To create a github.io personal blog site, your Jekyll blog should be
on the master branch of your Git repository. The repository should be
named `username.github.io` on GitHub. If everything is setup correctly
you can then publish your Jekyll blog by adding a remote for GitHub
and pushing your files up. If you use the `hub` gem (a gem for interacting with git and GitHub),
you can go from start to finish with a few simple commands. Make sure
to change the first line to reflect your username. 

[source,bash]
------
$ export USERNAME=xrd 
$ jekyll new $USERNAME.github.io
$ cd $USERNAME.github.io
$ git init
$ git commit -m "Initial checkin" -a
$ gem install hub
$ hub create  # You'll need to login here...
$ sleep $((10*60)) && open $USERNAME.github.io
------

The second to the last line creates a repository on GitHub for you
with the same name as the directory. That last line sleeps for 10
minutes while your github.io site is provisioned on GitHub, and then
opens the site in your browser for you. It can take ten minutes for
GitHub to configure your site the first time, but subsequent content
pushes will be reflected immediately. 

==== Hosting On Your Own Domain

To host a blog on your own domain name, you need to use the `gh-pages`
branch inside your repository. You need to create a CNAME file in your
repository, and then finally establish DNS settings to point your domain to
the GitHub servers. 

===== The gh-pages branch

To work on the gh-pages branch, check it out and create the branch
inside your repository. 

[source,bash]
-----
$ git checkout -b gh-pages
$ rake post title="My next big blog post"
$ git add _posts
$ git commit -m "Added my next big blog post"
$ git push -u origin gh-pages
-----

You will need to always remember to work on the gh-pages branch; if
this repository is only used as a blog, then this probably is not an
issue. Adding the `-u` switch will make sure that git always pushes up
the gh-pages branch whenever you do a push.

===== The CNAME file

The CNAME file is a simple text file with the domain name inside of
it. 

[source,bash]
-----
$ echo 'mydomain.com' > CNAME
$ git add CNAME
$ git commit -m "Added CNAME"
$ git push
-----

Once you have pushed the CNAME file to your repository, you can verify
that GitHub thinks the blog is established correctly by visiting the
admin page of your repository. An easy way to get there is using the
`github` gem, no longer actively maintained but still a useful command
line tool.

[source,bash]
-----
$ gem install github
$ github admin # Opens up https://github.com/username/repo/settings
-----

The github gem is a useful command line tool, but unfortunately it is
tied to an older version of the GitHub API, which means the documented
functionality is often incorrect. 

If your blog is correctly setup, you will see something like Figure 3
in the middle of your settings page.

[[settings-jekyll-blog]]
.Settings for a Jekyll blog
image::images/jekyll-settings.png[Settings for a Jekyll blog]

GitHub has properly recognized the CNAME file and will accept requests
made to that host on its servers. We are still not yet complete,
however, in that we need to make sure the DNS is established for our site.

===== DNS Settings

Generally, establishing DNS settings for your site is straightforward.
It is easiest if you are setting up DNS with a *subdomain* as opposed
to an *apex domain*. To be more concrete, an apex domain is a site
like mypersonaldomain.com, while a subdomain would be
blog.mypersonaldomain.com. 

Setting up a blog on a subdomain is simple: create a CNAME record in DNS that points
to `username.github.io`. 

For an apex domain, things are slightly more complicated. You must create DNS
A records to point to these IP addresses: `192.30.252.153` and
`192.30.252.154`.  These are the IP addresses right now; there is
always the possibility that GitHub could change these at some point in
the future. For this reason, hosting on apex domains is risky. If
GitHub needed to change their IP addresses (say during a denial of
service attack), you would need to respond to this, and deal with the
DNS propagation issues. If you instead use a subdomain, the CNAME
record will automatically redirect to the correct IP even if that is
changed by GitHub.

This is all well documented on the https://help.github.com/articles/setting-up-a-custom-domain-with-github-pages:[GitHub blog].

===== Problems with YML and YAML and Liquid

* No comments (JSON has the same problem...)
 * reading in parsing, then writing out, loses all the comments!
 * use `comment: "some comment here"` for comments. 

===== Capturing Content

VERIFY THIS STATEMENT

There is no support for partials.

[source,html]
{% capture sidebar %}{% include blog.md %}{% endcapture %}
<div style="text-align: left">
{{ sidebar | Markdownify }}
</div>

==== Converters

There are many tools which can be used to import an existing blog into
Jekyll. As Jekyll is a simple format, you just need to pull the
relevant pieces (the post itself, and associated metadata like the
post title, publishing date, etc.) and then put them into the simple
markdown format. 

==== Wordpress to Jekyll


The most popular importer is the Wordpress importer. You will need the 
the 'jekyll-import' gem, which is installed separately from the jekyll
gem. If you have installed the `github-pages` gem then the importers
are installed alongside the other tools packaged with this bundle.

===== Importing with direct database access

Once you have the `jekyll-import` gem, you can convert a Wordpress
blog using a command like this:

[source,bash]
----
 ruby -rubygems -e 'require "jekyll-import";
    JekyllImport::Importers::WordPress.run({
      "dbname"   => "wordpress",
      "user"     => "hastie",
      "password" => "lanyon",
      "host"     => "localhost",
      "status"         => ["publish"]
    })'
----

This command will import from an existing Wordpress installation,
provided that your ruby code can access your database. This will work if you can
log into the server itself and run the command on the server, or if
the database is accessible across the network (which is generally bad
practice when hosting Wordpress!). 

Note the status option: this specifies that imported pages and posts
are published automatically. More specifically, the YAML for each file
will specify `published: true` which will publish the page or post
into your blog. If you want to review each item individually, you can
specify a status of `private` which will export the pages into Jekyll
but leave them unpublished. Remember that if your repository is
public, they will not be listed on the blog but can still be seen if
someone peruses the source code for your blog on GitHub.  

There are many more options than listed here. For example, by default,
the Wordpress-Jekyll importer imports categories from your Wordpress
database, but you can turn this off by specifying `"categories" =>
false`. 

===== Importing from the Wordpress XML

Another alternative is to export the entire database as an XML file.
Then, you can run the importer on that file.

[source,bash]
----
ruby -rubygems -e 'require "jekyll-import";
    JekyllImport::Importers::WordpressDotCom.run({
      "source" => "wordpress.xml",
      "no_fetch_images" => false,
      "assets_folder" => "assets"
    })'
----

This can be used to export files from a server which you don't
maintain, but works with sites you maintain and might be a more
plausible option than running against a database.

To export the XML file, visit the export page on your site
(https://BLOGNAME.com/wp-admin/export.php).

Like many free tools, there are definitvely limitation to using this
method of export. If your Wordpress site is anything beyond the
simplest of Wordpress sites then using this tool to import from
Wordpress means you will lose much of the metadata stored inside your
blog. This metadata can include pages, tags, custom fields, and image
attachments. 

If you want to keep this metadata, then you might
consider another import option like `Exitwp`. Exitwp is a python tool 
which provides a much higher level of fidelity between the original
Wordpress site and the final Jekyll site, but has a longer learning
curve and option set.

==== Exporting from Worpdress alternatives

If you use another blog format other than Wordpress, chances are there
is a Jekyll importer for it. Jekyll has dozens of importers, well
documented on the Jekyll importer site http://import.jekyllrb.com/. 

For example, this command line example from the importer site exports
from Tumblr blogs.

[source,ruby]
------
$ ruby -rubygems -e 'require "jekyll-import";
    JekyllImport::Importers::Tumblr.run({
      "url"            => "http://myblog.tumblr.com",
      "format"         => "html", # or "md"
      "grab_images"    => false,  # whether to download images as well.
      "add_highlights" => false,  # whether to wrap code blocks (indented 4 spaces) in a Liquid "highlight" tag
      "rewrite_urls"   => false   # whether to write pages that redirect from the old Tumblr paths to the new Jekyll paths
    })'
------

Exporting from Tumblr is considerably easier than Wordpress. The
Tumblr exporter scrapes all public posts from the blog, and then
converts to a Jekyll compatible post format.

=== Scraping a site into Jekyll

If you are stuck with a site that does not fit any of the standard
importers, you could write your own importer by perusing the
http://github.com/jekyll/jekyll-import[source of the Jekyll
importers on GitHub]. This is probably the right way to 
build an importer if you plan on letting others use it, as it will
extend several jekyll importer classes already available to make
importing standard for other contributors. Learning all the existing
methods and reading through the dozens of samples can be a lot of
work, however; another option is just to write out our files
respecting the very simple format required by Jekyll. As we are
programmers in the true sense of the word we embrace and accept our
laziness and choose the second route. Let's write some code to scrape
and generate a Jekyll site.

Almost fifteen years ago while traveling in Brazil I grew increasingly
frustrated with the guide books I used. It seemed like every time I
went to a restaurant recommended by a guidebook I left the restaurant
thinking "well, either they paid for that review or the review was
written several years ago when this restaurant had a different owner."
To address this discrepancy between reviews and realities, I built a
site called ByTravelers.com. The idea was that travelers could use
ByTravelers to record their experiences and easily share their
experiences with their friends and families (replacing the long emails
they used to send) and that that information would then become an
authentication source of information about good and bad travel
experiences. 

I used the most advanced technologies
available at the time, specifically a web server called
http://en.wikipedia.org/wiki/Roxen_(web_server)[Roxen] featuring
a dynamic language called Pike back when the web was dominated by one
dynamic language called Perl. The site had ambitions greater than the
talents of its designer, but suprisingly, a modest number of people
found the site and started 
using it to track the experiences and simultaneously offer unbiased
reviews of their traveling histories. It was exciting to see people
creating content on their travels to China, Prague, and Cuba, and I
vowed to visit Bhutan at least once in my lifetime after reading one
particularly vivid account from an unknown contributor.

One of the problems with build on top of a web server and language
like Roxen and Pike that never achieved critical mass in any way is
that maintenance was a challenge. After moving back to the US and
moving my hosting servers several times, I lost access to the source
code (this was long before GitHub or even Git) and I lost access to
the database and ByTravelers.com settled into oblivion.

Or, so I thought. One day I decided to look up ByTravelers on
Archive.org, the Internet Archive. I found that almost all of the
articles were listed there and available. Even though we have lost the
source code and database, could we recover the site from just the
Internet Archive? Let's retrieve the articles from the Internet
Archive and make them into a modern Jekyll site. 

===== Jekyll scraping tactics

We'll use Ruby to scrape the site; Ruby has some intuitive gems like
mechanize which provide automation of web clients. There is an API for
the Internet Archive, but I found it flakey and unreliable. Scraping
the site itself works well, but to reduce load on the archive, we'll
cache our results using a gem called `VCR` (typically used to cached
results from hitting a web service during test runs but perfectly
capable here as well). In addition, as we'll find out, when you scrape
HTML you can retrieve text which crashes the markdown parser, so we
will want to write a few tests to make sure our scraping tool handles
these edge cases properly.

To write our parser, we will need to look at the structure of the
archive presented on Archive.org. If we start on Archive.org, and
enter "bytravelers.com" into the search box in the middle of the page,
and then click "BROWSE HISTORY" we will be presented with a calendar
view which shows all the pages scraped by the Internet Archive for
this site. 

[[calendar-view-archive]]
.Calendar view of Archive.org
image::images/jekyll-bytravelers-archive.png[The calendar view for Archive.org ]

In the middle of 2003 I took down the server, intending to
upgrade it to another set of technologies, and never got around to
completing this migration, and then lost the data. If we click on the
calendar item on June 6th, 2003, we will see a view of the data that
was more or less complete at the height of the site's functionality
and data. There are a few broken links to images, but otherwise the
site is functionally archived inside Archive.org

[[calendar-view-bytravelers]]
.Archive of ByTravelers.com on Archive.org
image::images/jekyll-bytravelers-jun6.png[Archive of Bytravelers.com on Archive.org]

Taking the URL from Chrome, we can use this as our starting point for
scraping. Clicking around throughout the site, it becomes evident that
each URLs to a journal entry uses a standard format; in other words, 
`http://www.bytravelers.com/journal/entry/56` indicates the 56th
journal item stored on the site. With this knowledge in hand, we can
iterate over the first hundred or so URLs easily. 

Going to one of these pages through the archived site, it is useful to
view the source of the page and start to understand the structure of a
page which we can then use when pointing our mechanize scraper at the
page to pull out content. Any modern web browser supports a debug mode, and Chrome (my
browser of choice) supports this as well. If we hold down the control
key and click (at least on Mac OSX; righting-click on Windows or
Linux works in the same way) into the "body" of a journal entry on its
page, we will see a context menu that gives us the option to "Inspect Element".
Chosing this option brings up the Chrome Developer Tools and shows us
the HTML code of the page pretty printed for us. There are a few other
items of note if we hover over any of the printed items toward the
bottom. As we moved our mouse over the `<p></p>` items, we see a
highlight applied to the page above, indicating the visual result once
rendered in a browser of this specific this HTML code. 

[[inspecting-page-structure]]
.Inspecting Page Structure
image::images/jekyll-chrome-inspector.png[Inspecting Page Structure]

Moving over different places in the HTML code displays different areas of our
page; finding our way to the `<tr>` tag above the large number of
`<td>`'s gives us access to the "body" of the post. Once there, you
can see at the very bottom of the frame a hierarchy like `html body
table tbody tr td font table tbody tr` which tells us clues about the
path we need to take inside the DOM to reach this particular piece of content. With these
indications in hand, we can start to write our parser to extract this
text from pages scraped from the archive.

====== Writing our Parser

Let's start by writing a parser class. You might raise an eyebrow and
think that making our scraper script into an object oriented program
is overkill. We'll prove this is a helpful approach because we
can instantiate the parser class inside a runner script, but we
can also then instantiate the same class inside a test harness. As we will
find out, there are edge cases we will need to cover when scraping
data and converting it to Markdown, and having a testable class structure will
help make our code testable in a way that a purely imperative script
would not.

[source,ruby]
-----
require 'rubygems'
require 'mechanize'
require 'vcr'

VCR.configure do |c|  # <1> 
  c.cassette_library_dir = 'cached'
  c.hook_into :webmock
end

class ByTravelersProcessor
  attr_accessor :mechanize  # <2>

  def initialize
    @mechanize = Mechanize.new { |agent| # <3>
      agent.user_agent_alias = 'Mac Safari'
    }
  end

  def run
    100.times do |i| 
      get_ith_page( i ) # <4>
    end
  end
  
  def get_ith_page( i )
    puts "Loading #{i}th page"
  end
  
end

  

-----

<1> VCR is a ruby library which caches HTTP requests. Typically used
inside of tests, it is also an easy way to cache an HTTP request that
you know will not change. Since these are pages stored inside an
archive over ten years ago, it is safe to cache them, and the polite
thing to do for an open system like Archive.org which relies on
donations to pay for their bandwidth. The code you see here is
boilerplate for configuring the VCR gem, loaded above.
<2> Our scraping is handled with the `mechanize` gem, and our class
should maintain a reference to the scraper by declaring it here.
<3> After our class is instantiated, we hook into the class
initialization stage and create our mechanize parser and assign it to
the class.
<4> As we noted above, we have about 100 pages stored in the archive
which we want to scrape. We loop 100 times over a function called
`get_ith_page` which will do the scraping for us. Right now this
function just prints out the index it is supposed to scrape.

===== Installation of our libraries

Like other chapters which use Ruby, we create a `Gemfile` to manage
our dependencies and then install them using the `bundle` command.

[source,bash]
-----
$ printf "source 'https://rubygems.org'\ngem 'vcr'\ngem 'mechanize'\ngem 'webmock'\n" >> Gemfile
$ bundle
-----

===== The Runner

Our runner is simple (this means our test cases will be too).

[source,ruby]
-----
require 'rubygems'
require 'bundler/setup'
require './scraper'

btp = ByTravelersProcessor.new()
btp.run()

-----

If we run this code now, we will just see our debug output.

[source,bash]
-----
$ ruby run.rb
...
Loading 91th page
Loading 92th page
Loading 93th page
Loading 94th page
Loading 95th page
Loading 96th page
Loading 97th page
Loading 98th page
Loading 99th page
...
-----

===== Implementing get_ith_page

Now let's write the code which pulls out the information for the body
and the title by implementing the `get_ith_page` method.

[source,ruby]
-----
  def process( i, title, body )
    puts "(#{i}) #{title.text().strip()} :: #{body.text().strip()[0...50]}" # <4>
  end
  
  def get_ith_page( i )
    root = "https://web.archive.org/web/20030502080831/http://www.bytravelers.com/journal/entry/#{i}"
    begin
      VCR.use_cassette("bt_#{i}") do # <1> 
        mechanize.get( root ) do |page|
          rows = ( page / "table[valign=top] tr" )   # <2>
          if rows and rows.length > 3
            process( i, rows[1], rows[4] ) # <3>
          end
        end
      end
    rescue Exception => e
      puts "Got an exception, skipping index #{i}"
    end
    
  end
-----

<1> First, we load up a VCR cassette; this code says "store any HTTP requests
inside my cassette directory ('cached', specified in the configure
stage) under the name bt_#{index}". In more concrete terms, the first
page loaded by our script will be cached and saved in a file at the
path `cached/bt_1.yml` (VCR adds the yml extension because it stores
the results as a structured YAML file).
<2> Once we have loaded the page we see one of the powerful features
of mechanize footnote:[Actually, this is handled by the Nokogiri parser, but
Mechanizes exposes it seamlessly], a simple page searching syntax. If
we provide the code `page / "table[valign=top] tr"` what we are doing
is searching inside the page for a tag like `<table valign="top">` and
then finding all the `<tr>` tags inside that. Recalling the DOM
hierarchy we saw inside the Chrome Inspector, we can start to see how
we will easily retrieve content from a scraped page.
<3> We then take the 2nd and 5th (ruby uses zero-based offsets) rows, and
process it using a method called `process` which, you guessed it,
process them as title and body.
<4> The `process` method takes the retrieved DOM nodes and
converts them to pure text (as opposed to leaving us with the HTML tags)
and then strips whitespace from the front and end, and then prints the
index in parentheses, the title and the first 50 characters of the body.

If we run our code now, we will see the body of our journal entries.

[source,bash]
-------
$ ruby run.rb
(4) Third day in Salvador :: I'm now entering the my third day in Salvador.  Th
(15) The Hill-Tribes of Northern Thailand :: I had heard about the hill-tribes in 
northern Tha
(22) Passion Play of Oberammergau :: On Sunday, Sept. 17 Jeanne picked up Vic at Jackie
(23) "Angrezis in Bharat" :: Translation -  "Foreigners in India"Well since we 
(24) Cuba - the good and bad :: April 1999Cuba, what an interesting place??!!
My a
(25) Nemaste :: Oct/Nov 2000"NEPAL"We spent our first 3 days in Ba
(26) Mexico/Belize/Guatemala :: Feb/Mar 1999Dear All
Well it´s been six weeks on t
(27) South Africa :: Apr/May 1999I got in from South Africa a few days 
...
-------

The first time we run this, we will see a slow march as Mechanize
grabs each page from the Archive.org server. The next time we run our
parser, however, things will be much faster. We have cached all the
pages and so instead of doing a slow network crawl we are now speeding
across our local filesystem, reading files from disk and simulating
our network connection. Our client code does not have to change at
all, the real power of the VCR gem.

Now let's break the title and body processing into separate methods.
Add a method called `process_title` and add that into the `get_ith_page` method underneath
the renamed `process` method now called `process_body`.

[source,ruby]
-----
  def run
    100.times do |i| 
      get_ith_page( i ) 
    end
    100.times do |i|
      if pages[i]
        puts "(#{i}) #{pages[i][0]} :: #{pages[i][1][0...50]}" # <4>
      end
    end
  end

  def process_body( i, row ) # <1>
    body = ""  
    if row
      ( row / "p" ).each do |p|
        text = p.text()
        text.strip!
        text.gsub!( /\*\s*/, '' )
        body += text + "\n\n"
      end
    end
    body
  end

  def process_title( i, title )
    title = title
    if title
      title.gsub!( /Title:/, "" )
      title.strip!
    end
    title # <2>
  end
  
  def get_ith_page( i )
    root = "https://web.archive.org/web/20030502080831/http://www.bytravelers.com/journal/entry/#{i}"
    begin
      VCR.use_cassette("bt_#{i}") do 
        mechanize.get( root ) do |page|
          rows = ( page / "table[valign=top] tr" ) 
          if rows and rows.length > 3
            body = process_body( i, rows[4] ) 
            title = process_title( i, rows[1] )
            pages[ i ] = [ title, body ] # <3>
          end
        end
      end
    rescue Exception => e
    end
    
  end
  
-----

We've modified the `get_ith_page` method to save each page as a tuple
(the title and body) and then print them out after processing inside
the `run` method.

<1> Our process body might look a little excessive. Why not just
return the result of `row.text()`? The reason is that markdown
is very specific about the format it requires for text formatting.
Each block of text separated by two newlines will be formatted within
`<p>` tags. Unfortunately, Mechanize and Nokogiri don't return text
formatted that way, so this function retrieves each `<p>` tag we
scraped, strips whitespace from the ends, and then adds it back to a
body variable. If you scrape text from a site like we are doing here,
you might need to normalize the text in a similar way.
<2> Do the same type of processing with the title. With this site
there are occasionally titles which include the word "Title:" in the
title itself (authors have to be forgiven for their own formatting
quirks) so strip that out if we see it there.
<3> Keep track of each page in an array with each item of the array
containing the title and body. We can then use this processed data
later to build out our posts.
<4> At the end of processing, just print out the processed data we
saved to verify we are finding the right structure in our pages.

If we re-run this script we will see identical output to the prior
run, but now we are storing the information in an array and can use it
to write out our Markdown files.

===== Generating Markdown

Now that we have our information parsed out, we can generate Markdown
from it. As we've seen, Jekyll Markdown files are very simple: just a
bit of YAML at the beginning, with text content following, formatted as
Markdown. 

We need to create a Git repository which we can push into GitHub.
There is no reason why we cannot store our scraper scripts inside it,
so let's just add the files to the same directory

[source,bash]
------
$ git init
$ mkdir _posts
$ printf "_site" >> .gitignore
$ git add .gitignore
$ git commit -m "Initial checkin"
------

To generate Markdown posts, edit the `run` method to write
out the files after we have retrieved and parsed the pages from Archive.org.

[source,ruby]
-----
  def write_post( page )
    title = page[0]
    body = page[1]
    creation_date = page[2]

    title.gsub!( /"/, '' ) # <2>
    
    template = <<"TEMPLATE"  # <3>
---
layout: default
title: "#{title}"
published: false
---

#{body}
TEMPLATE

    title_for_filename = title.downcase.gsub( /,+/, '' ).gsub( /[\s\/\:\;]+/, '-') # <3>
    filename = "_posts/#{creation_date}-#{title_for_filename}.md"
    File.open( filename, "w+" ) do |f|
      f.write template
    end
  end

  def run
    100.times do |i| 
      get_ith_page( i ) 
    end
    100.times do |i|
      if pages[i]
        write_post( pages[i] ) # <1>
      end
    end
  end

  def process_creation_date( i, row )
    location, creation_date = row.text().split /last updated on:/ # <5>
    creation_date.strip()
  end  
  
-----

<1> First, we modify the `run` method to call our new `write_post`
method. This method is reponsible for writing out each datum in the
array of processed data to a markdown file.
<2> We enclose the title inside the YAML inside of double quotes, so
to make sure this does not conflict with the YAML parser we remove
double quotes from the title here. We need to do this when we generate
the filename later, so we use the `gsub!` method which modifies the
string itself (rather than returning a new value but leaving the
existing string intact).
<2> Inside the `write_post` method we create a "heredoc" template, and
then stick values inside of it. Heredocs provide a more readable way
to write out larger textual data, especially those with newlines.
Heredocs simply start with a tag and then end the contents with the same tag
("TEMPLATE" here), and everything in between is treated as a single
string. 
<3> Jekyll expects markdown filenames to have a specific format. We need
to modify the title by remove commas and quotes, and then converting
whitespace, colons and semicolons to hyphen characters. We also need
the creation date, which we retrieve in a later call, and parameterize
the title with that information. Then we write out the file.
<4> Inside our new `process_creation_date` method we extract the
creation date from the scraped data. We don't show it here because it
is trivial, but after the `process_body` method call (which is inside
the `get_ith_page` method) we added a call to this new function,
giving it `i` and `row[3]` as the arguments. 

We now have the posts generated properly, but we don't have an entry
page into the blog. We can create a `index.md` file which just
displays an index of all the blog posts. Inside this file we will use
Liquid Tags to generate that list of posts. Notice that the site
variable is populated with the list of posts automatically (Jekyll
loads these up as long as they are in the `_posts` directory). We
generate a link with the post URL, create a teaser from the content by
generating a snippet of the body using the truncate method. Then we
indicate the date that file was processed.  Liquid provides a nice set
of tools to convert and process text using the pipe character which
allow you to build complex structures when combined with the looping
constructs you see here.

There are a wide swath of constructs available with Liquid Templates.
You can review the documentation for specifics. One common source of
confusion when first learning Liquid is the difference between output
tags and logic tags. Output tags use double braces surrounding the
content (`{{ site.title }}`) while logic tags use a brace and percent
symbol (`{% if site.title %}`). As you might expect, output tags place
some type of visible output into the page, and logic tags perform some
logic operation, like conditionals or loops. 

[source,html]
-----
---
layout: default
---

<h1>ByTravelers.com</h1>

Crowd sourced travel information.

<br/>

<div>
{% for post in site.posts %}
<a href="{{ post.url }}"><h2> {{ post.title }} </h2></a>
{{ post.content | strip_html | truncatewords: 40 }}
<br/>
<em>Posted on {{ post.date | date_to_string }}</em>
<br/>
{% endfor %}
</div>


-----

The above template has both output and logic tags. We see a logic tag
in the form of `{% for ... %}` which loops over each post. Jekyll will
process the entire posts directory and provide it to pages inside the
`site.posts` variable, and the `for` logic tag allows us to iterate
over them. Remember that if we use a `{% for ... %}` tag we need to
"close" the tag with a matching `{% endfor %}` tag. Inside of our for
loop we have several output tags: `{{ post.url }}` outputs the post
URL associated with a post, for example. We also have "filters" which
are methods defined to process data. One such filter is the
`strip_html` filter which you might guess strips out HTML text,
converting it to escaped text. This is necessary when your text could
include HTML tags. You'll also notice that filters can be "chained";
we process the body with the `strip_html` filter and then truncate the
text by 40 characters using the `truncatewords:40` filter.

We also need to create a *default* layout, so create this inside the
`_layouts` directory with the filename `default.html`. 

[source,html]
-----
<html>
<head>
<title>ByTravelers.com</title>
</head>

<body>

{{ content }}

</body>
</html>

-----

This file is almost pure HTML, with only the `{{ content }}` tag. When
we specify `default` as the layout inside YAML for a Markdown file,
the Markdown text is converted to HTML, and then this layout file is
wrapped around it. Notice this default layout is the same layout we
have used inside our post files. 

Finally, in order to convey that this is a Jekyll repository to both
the command line Jekyll processor and GitHub service, we need to
create a `_config.yml` file. We saw a simple version of this file
earlier and can reuse this almost verbatim, changing only the name.

[source,yaml]
-----
name: ByTravelers.com
markdown: redcarpet
pygments: true
-----

Taking a moment to add our files to the Git repository, we can then
take a look at our site using the `jekyll` command line tool.

[source,bash]
----
$ git add .
$ git commit -m "Make this into a Jekyll site"
...
$ jekyll serve --watch
Configuration file: /Users/xrdawson/Projects/GithubBook/1234000000486/support/jekyll-parser/_config.yml
            Source: /Users/xrdawson/Projects/GithubBook/1234000000486/support/jekyll-parser
       Destination: /Users/xrdawson/Projects/GithubBook/1234000000486/support/jekyll-parser/_site
      Generating... done.
 Auto-regeneration: enabled
    Server address: http://0.0.0.0:4000
  Server running... press ctrl-c to stop.
----

We've started the Jekyll server in "watch" mode which means the site will
be automatically regenerated if we edit the source files. Let's take a
look at the site as currently configured on *http://localhost:4000*.

[[no-posts]]
.No posts at all
image::images/jekyll-no-posts.png[No posts at all]

There are no posts! Ah, we elected to keep posts "unpublished" for now
to review them before making them public. If we edit any file
individually and change the line `published: false` inside our YFM to
`published: true` then we will see that this file becomes available
inside our site. Let's do this for three of the files. Notice the
server regenerates our files each time we change one of them.

[source,bash]
-------
...
      Regenerating: 1 files at 2014-06-20 12:54:52 ...done.
      Regenerating: 2 files at 2014-06-20 12:55:03 ...done.
      Regenerating: 1 files at 2014-06-20 12:55:15 ...done.
      Regenerating: 4 files at 2014-06-20 12:55:15 ...done.
...
-------

And, if we reload our page we'll see them listed inside our index.

[[publishing-single-post]]
.Publishing a single post
image::images/jekyll-got-posts.png[Publishing some of the posts]

If we trust that all these posts are correct, we can change the
`scraper.rb` script to make them all public (inside the heredoc
template, just change the published flag), or we could change files
individually by hand as we did here.

Taking a look at the blog post itself, we see this after clicking on
the first link.

[[not-so-beautiful]]
.Not the best formatting
image::images/jekyll-unformatted-post.png[Not the best formatting]

Not very pretty at all. We can beautiful this by adding some styling
to the page. We'll use Bootstrap, the most popular CSS framework on
GitHub. To start, edit the layout to include Bootstrap from the
Bootstrap CDN. And, add a `container` class around the content. 

[source,html]
-----
<html>
<head>
<title>ByTravelers.com</title>

<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">

</head>

<body>

{{ content }}

</body>
</html>

-----

Notice that our files are regenerated in the terminal window with
`jekyll serve -w`. Refreshing the page shows some improvement, but we
can do better. Let's make a front page which shows just the ten most
recent post, and an archive page which shows all the posts in reverse
chronological order.

First, copy the existing `index.md` file to a file named `archive.md`.
Our current index looks just like our archive page needs to be. 
To make the front page with ten posts change the `{% for post in
site.posts %}` tag to `{% for post in site.posts | limit:10 %}`. This
limits us to ten posts. Add a link to `archive.html` at the bottom of
our `index.md` file.

If we look at any of the pages we've scraped, they are now centered
inside a box, but we don't have titles or anything else about the
journal entry. Add a layout file just for posts by creating a file
called `post.html` inside of the `_layouts` directory with the
following contents.

[source,html]
-----
---
layout: default
---

<h1>{{ page.title }}</h1>

{{ content }}


-----

Notice also that this layout inherits the default layout. You can
imagine wrapping many layouts within layouts to build up complicated
output trees, but in this case we can now manage a base layout,
including all the CSS and other complementary files associated with
our site, and automatically propagate changes down into lower layout files.

Add these changes to the index, and commit them.

[source,bash]
-----
$ git add .
$ git commit -m "Added layout specific to posts"
-----

Now that we have a post layout, we will need to adjust our post files
to use this layout as right now they specify `layout: default` inside
their YAML Front Matter. You might groan at the thought of editing all the
files individually, but we don't need to go through that much effort
as it turns out. If we make a one line change to our `scraper.rb`
script (inside the `write_post` method) we can run the script again, and all our files will
automatically be updated. As we committed them to our local git
repository, we can also use tools like `git diff` to verify the
changes we made were the correct ones.

[source,ruby]
-----

    title.gsub!( /"/, '' )
    
    template = <<"TEMPLATE" 
---
layout: post    #  <---- Set our layout variable to "post"
title: "#{title}"  
published: true
---

#{body}
TEMPLATE

-----

If we then run `ruby scraper.rb` we will see something like
`Regenerating: 31 files at 2014-06-24 09:00:39 ...done.` indicating
that our post files have changed. We can also verify that we made the
correct changes by using the `git diff _posts` command. The result
will be something like the following.

[source,bash]
------
$ git diff _posts
diff --git a/support/jekyll-parser/_posts/2000-05-23-third-day-in-salvador.md b/support/jekyll-parser/_posts/2000-05-23-third-day-in-salvador.md
index 1873972..a4dbc21 100644
--- a/support/jekyll-parser/_posts/2000-05-23-third-day-in-salvador.md
+++ b/support/jekyll-parser/_posts/2000-05-23-third-day-in-salvador.md
@@ -1,10 +1,16 @@
 ---
-layout: post
+layout: post    #  <---- Set our layout variable to "post"
 published: true
 ---
...
------

The astute amongst you will also note that this shows we can add
comments inside of our YAML Front Matter when needed. 

===== Customizing our CSS 

Adding a CSS framework like Bootstrap helps things considerably, but
we should match the original colors as well. The easiest way to get
this information is to again view the site HTML using your browser's
developer tools. On Chrome we can see that in the original body we
hard code colors for the body, text and links. 

[[hard-coding-colors]]
.Hard coding colors into our HTML
image::images/jekyll-hardcoded-colors.png[Hard coding colors into our HTML]

We need to convert this into the modern equivalent CSS and we can then
add this a CSS file and include it inside all our pages by adding
a link from the `default.html` template. Make a new directory inside
called `assets/css` and write a file called `site.css` and include the
CSS to match our original site. The choice of using `assets/css` as
the directory structure is completely arbitrary; we could have chosen
any structure we wanted and as long as the reference was correct it
would have worked with our HTML templates.

[source,css]
-----
body {
color: #000000;
background-color: #CCCC99;
}

a {
color: #603;
}

-----

Then, modify the `default.html` template and include the new CSS file
to allow our style changes to "cascade" to all our other files.

[source,css]
-----
...
<title>ByTravelers.com</title>

<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<link href="/assets/css/site.css" rel="stylesheet">

</head>
...
-----

===== Adding in original images

Our site is bare beyond text and the original colors; adding the
images would add some pop. We can easily modify our `scraper.rb`
script and pull down the original images from our site and then
republish them into our new Jekyll blog. Taking a look at the archived
site, note that each title has an image to the left of it. If we
customize our `process_title` method we can retrieve these images and
then publish them into our blog.

Finding the image is easy: `img = ( title/ "img" )` will retrieve an
"img" tag from the title as passed to us. Printing out the element
using `puts` is simple way to view the contents of the elements, one
of which looks like this `<img
src="/web/20030502075943im_/http://www.bytravelers.com/images/pro/book.gif">`
We can then dig into the element using syntax like `img.attr('src')`
and get to the actual source of the image. We'll need to append the
base site URL to this and can then retrieve the image from
archive.org. 

Unfortunately, the VCR gem does not easily allow us to 
make requests which are not captured. There are methods in VCR to
ignore requests, but without heavily refactoring our `get_ith_method`.
Instead we cheat by using a command line tool called `wget` to
download the image. The VCR gem works by hooking into ruby libraries
which make HTTP calls; by using the `wget` tool we can avoid using
Ruby for a moment and download the file manually.

[source,ruby]
-----
...
  def process_title( i, title )
    img = ( title / "img" ) # <1>
    src = img.attr('src').text()
    filename = src.split( "/" ).pop
    
    output = "assets/images/"
    full = File.join( output, filename ) # <2>
    
    unless File.exists? full
      root = "https://web.archive.org"
      remote = root + src
      contents = `wget --quiet -O #{full} #{remote}`  # <3>
    end
    
    title = title.text()
    if title
      title.gsub!( /Title:/, "" )
      title.strip!
    end
    [ title, filename ]  # <4>
    
  end
...
-----

<1> First, use the HTML node and extract the `img` tag from it. We
then process the result, picking the `src` attribute from the tag, and
then split it up by slash characters and pull off the last item
returning just the filename.
<2> We then generate a path for the image. We chose `assets/images`,
which keeps all our assets (like our CSS file) in a common place.
<3> The `wget` command requires a full remote URL and the path we
created previously. We give it the `--quiet` switch to reduce noise
during our processing.
<4> We will be placing the image into the template, so we want to
return it with the title as processed data.

Once we have processed the information, we will need to modify the
post template. We passed back the image inside the processed data from
the `process_title` method. Ruby is an untyped language and this makes
it so that even though initially we were passing back a string result
from `process_title` and are now passing back an array of strings, we
don't need to change the `get_ith_page` which assembles the results of
our processing functions and puts them into the `page` array. When we
iterate over the `page` result later, we should interpret the first
element differently and pull the first item out as our title, and use
the second item as the image for the post. This can all happen inside
our `write_post` method.

[source,ruby]
-----
...
  def write_post( page )
    title = page[0][0]  # <1>
    image = page[0][1]
    body = page[1]
    creation_date = page[2]
    
    title.gsub!( /"/, '' )
    
    template = <<"TEMPLATE" 
---
layout: post   
title: "#{title}"  
published: true
image: #{image}   # <2>
---

#{body}
TEMPLATE

...
-----

<1> As we mentioned, the first item in the array we receive is now the
title and image packages as another array. We pull the first item out
as the title text, and use the next item in the secondary array as the
image.
<2> What do we do with the image? Let's put it into the YAML Front
Matter. We can then utilize it from within our `post.html` layout file
using Liquid tags.

Now, we modify our `post.html` layout to include the image near the
title.

[source,html]
-----
---
layout: default
---

<h1>{{ page.title }}</h1>

<img src="/assets/images/{{ page.image }}">

{{ content }}


-----

We use the Liquid template tags `{{ page.image }}` to retrieve the
image from our YFM and build an image tag inside our template.

We can also reuse this image on our index page (`index.md`).

[source,html]
-----
---
layout: default
---

<h1>ByTravelers.com</h1>

Crowd sourced travel information.

<br/>

<div>
{% for post in site.posts %}
<a href="{{ post.url }}"><h2> {{ post.title }} </h2></a>
<img src="/assets/images/{{ post.image }}">
{{ post.content | strip_html | truncatewords: 40 }}
<br/>
<em>Posted on {{ post.date | date_to_string }}</em>
<br/>
{% endfor %}
</div>


-----

Note that in this case the variable is presented as `post.image` as
compared to `page.image` when we are inside a post. Jekyll and Liquid
are not consistent here, so caveat emptor.

Our blog definitely has more life when we add in the original colors and
images. It still looks like a blog from the last millenium, but it is
an improvement.

[[jekyll-now-livelier]]
.Restoring the original colors and images
image::images/jekyll-now-livelier.png[Restoring our blog using images and colors]

===== Adding maps

This is a site about travel information, so it makes sense to add maps
as well. We can process the location information we retrieved from the
archived site and add a map image. 

Add a new function called `process_location` and place it underneath
the `process_creation_date` method inside the `get_ith_page` method.

[source,ruby]
-----
...
  def process_location( i, row )
    location, creation_date = row.text().split /last updated on:/  # <1>

    location.gsub!( /Concerning: /, "" ) # <2>
    location.strip!
    return location # <3>
  end  
...
-----

<1> As we did in the `process_creation_date` method, we grab the row
and split it in two pieces. This time we are only interested in the
first element, the location.
<2> Each location string starts with the text "Concerning: " so we
remove that here.
<3> Return the result

Now that we have the location, we need to insert it into the post
itself. Once again we will place it inside the YFM. Modify the
`write_post` method to grab the location from the array argument, and
use that in the template inside the YFM.

[source,ruby]
-----
...
  def write_post( page )
    title = page[0][0]  
    image = page[0][1]
    body = page[1]
    creation_date = page[2]
    location = page[3]
    
    title.gsub!( /"/, '' )
    
    template = <<"TEMPLATE" 
---
layout: post   
title: "#{title}"  
published: true
image: #{image}
location: #{location}
---

#{body}
TEMPLATE

...
-----

Then, inside the `post.html` file, add an image tag with the map. We'll use a
static image generated by Google Maps. We can utilize the location
item inside the YFM and generate a map footnote:[This idea was
modified from http://katydecorah.com/code/2013/09/06/google-maps-images-api-for-jekyll/::[a blog post on Katy Decorah's blog]].

[source,html]
----
---
layout: default
---

<h1>{{ page.title }}</h1>


{% if page.location %} 
<div>
<img src="http://maps.googleapis.com/maps/api/staticmap?center={{ page.location }}&zoom=13&size=400x100">
</div>
{% endif %}

<img src="/assets/images/{{ page.image }}">

{{ content }}


----

===== Inviting contributions via forking

When you publish a Jekyll blog, the fact that it is a repository on
GitHub makes it simple to manage and track changes. In addition,
because forking is a button click away, you can ask people to
contribute or make changes with very little friction.
You might have seen the banner
saying "Fork me on GitHub" on many a software project page hosted on
GitHub. We can motivate others to participate in our blog 
using pull requests. Let's add that as a final touch and
invite people to make contributions the GitHub way. The https://github.com/blog/273-github-ribbons:[GitHub blog
first posted these banners] and we'll use their code as-is inside our
`default.html` page.

[source,html]
-----
...
<body>

<a href="https://github.com/xrd/bytravelers.com"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png"></a>

<div class="container">
{{ content }}
...
-----

==== Publishing our blog to GitHub

Like any other GitHub repository, we can then publish our blog using
the same commands we saw with earlier repositories. Obviously you
should change the username and blog name to suit your own needs. 

[source,bash]
----
$ export BLOG_NAME=xrd/bytravelers.com
$ gem install hub
$ hub create $BLOG_NAME # You might need to login here
$ sleep $((10*60)) && open $BLOG_NAME
----

And, don't forget to setup DNS records and give yourself appropriate
time to let those records propagate out.

==== Summary

We've shown that we can quickly setup a blog on GitHub that has
version control built in. We've shown how to import blogs like
Wordpress into Jekyll. And, we've taken a site available only as an
archive on the Internet Archive and scraped the content, images and
even the colors, and then converted it to a Jekyll blog. Jekyll is a
simple tool for managing websites, but a hidden benefit is that
because Jekyll is so simple, you can easily write your own tools to
interact and build on top of Jekyll. Once our site is a repository on
GitHub, making changes yourself, or accepting them from other
contributors is as easy as clicking "Merge" on a pull request. 



